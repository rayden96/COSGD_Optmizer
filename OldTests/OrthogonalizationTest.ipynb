{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_grads(grads):\n",
    "    grads = torch.cat([grad.view(-1) for grad in grads])\n",
    "    return grads\n",
    "\n",
    "def unflatten_grads(flattened_grads, model):\n",
    "    grads = []\n",
    "    start = 0\n",
    "    for param in model.parameters():\n",
    "        end = start + param.numel()\n",
    "        grads.append(flattened_grads[start:end].view(param.size()))\n",
    "        start = end\n",
    "    return grads\n",
    "\n",
    "def sort_grads(grads, sort_order=True):\n",
    "    avg_abs = [torch.mean(torch.abs(grad)).item() for grad in grads]\n",
    "    order = sorted(range(len(avg_abs)), key=lambda i: avg_abs[i], reverse=sort_order)\n",
    "    return order\n",
    "\n",
    "def unsort_grads(grads, order):\n",
    "    unsorted_grads = [grads[i] for i in order]\n",
    "    return unsorted_grads\n",
    "\n",
    "def orthogonalize_grads(grads):\n",
    "    flattened_grads = [flatten_grads(cluster_grads) for cluster_grads in grads]\n",
    "\n",
    "    #sort the vectors by average absolute value in descending order\n",
    "    order = sort_grads(flattened_grads)\n",
    "    flattened_grads = [flattened_grads[i] for i in order]\n",
    "\n",
    "    #now we have a set of vectors, we can perform the gram schmidt process\n",
    "    ortho_grads = []\n",
    "    for i, grad in enumerate(flattened_grads):\n",
    "        for j in range(i):\n",
    "            #subtract the projection of the current vector onto the previous vectors\n",
    "            if torch.norm(ortho_grads[j]) != 0:\n",
    "                grad = grad - (grad @ ortho_grads[j]) / (ortho_grads[j] @ ortho_grads[j]) * ortho_grads[j]\n",
    "        ortho_grads.append(grad)\n",
    "    #sort the vectors back to their original order\n",
    "    ortho_grads = unsort_grads(ortho_grads, order)\n",
    "    return ortho_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing of the orthoganlization process\n",
    "\n",
    "Tests to be carried out:\n",
    "1. test orthogonalization algorithm as is, with many 0s and very small numbers \n",
    "2. Ensure any size tensor is passed in, flattened (keeping the seperate cluster vectors) and orthogonalized, and returned in the correct shape\n",
    "3. Ensure the vectors are orthogonalized and no overflows or division by 0 occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vectors:\n",
      "[tensor([0.3000, 0.7000, 0.6000, 0.9000, 0.1000]), tensor([-0.3000,  0.6000, -0.8000,  0.8000,  0.8000]), tensor([ 0.1000, -0.1000, -0.6000, -0.9000,  0.0000])]\n",
      "Orthogonalized vectors:\n",
      "[tensor([0.3000, 0.7000, 0.6000, 0.9000, 0.1000]), tensor([-0.4108,  0.3415, -1.0216,  0.4676,  0.7631]), tensor([ 0.3288,  0.3625, -0.1314, -0.3069,  0.0269])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[3, 5]}, size=[5]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(ortho_vectors)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#use the vectorized version of the orthogonalization function\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m ortho_vectors \u001b[38;5;241m=\u001b[39m \u001b[43morthogonalize_vectors_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorized Orthogonalized vectors:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(ortho_vectors)\n",
      "Cell \u001b[1;32mIn[25], line 24\u001b[0m, in \u001b[0;36morthogonalize_vectors_vectorized\u001b[1;34m(vectors)\u001b[0m\n\u001b[0;32m     21\u001b[0m prev_vectors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(vectors)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(vectors\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#subtract the projection of the current vector onto the previous vectors\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mortho_vectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m vectors[i] \u001b[38;5;241m-\u001b[39m (vectors[i] \u001b[38;5;241m@\u001b[39m prev_vectors\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m/\u001b[39m (prev_vectors \u001b[38;5;241m@\u001b[39m prev_vectors\u001b[38;5;241m.\u001b[39mt()) \u001b[38;5;241m@\u001b[39m prev_vectors)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m#update the previous vectors\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     prev_vectors[i] \u001b[38;5;241m=\u001b[39m ortho_vectors[i]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[3, 5]}, size=[5]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "#orthogonalization function that takes in a set of vectors and orthogonalizes them\n",
    "def orthogonalize_vectors(vectors):\n",
    "    ortho_vectors = []\n",
    "    for vector in vectors:\n",
    "        for ortho_vector in ortho_vectors:\n",
    "            #handle the case where the vector is all zeros\n",
    "            if torch.norm(ortho_vector) == 0:\n",
    "                continue\n",
    "            #subtract the projection of the current vector onto the previous vectors\n",
    "            vector = vector - ((vector @ ortho_vector) / (ortho_vector @ ortho_vector) * ortho_vector)\n",
    "        ortho_vectors.append(vector)\n",
    "    return ortho_vectors\n",
    "    \n",
    "#create a vectorized version of the orthogonalization function that does the work in parallel, dont include the normalization step\n",
    "def orthogonalize_vectors_vectorized(vectors):\n",
    "    #create a matrix of the vectors\n",
    "    vectors = torch.stack(vectors)\n",
    "    #create a matrix of the orthogonalized vectors\n",
    "    ortho_vectors = torch.zeros_like(vectors)\n",
    "    #create a matrix of the previous vectors\n",
    "    prev_vectors = torch.zeros_like(vectors)\n",
    "    for i in range(vectors.size(0)):\n",
    "        #subtract the projection of the current vector onto the previous vectors\n",
    "        ortho_vectors[i] = vectors[i] - (vectors[i] @ prev_vectors.t() / (prev_vectors @ prev_vectors.t()) @ prev_vectors)\n",
    "        #update the previous vectors\n",
    "        prev_vectors[i] = ortho_vectors[i]\n",
    "    return ortho_vectors\n",
    "\n",
    "#first test, create a random set of vectors and orthogonalize them, record the average change of elements in the vectors after orthogonalization\n",
    "# vectors = [torch.randn(10) for i in range(10)]\n",
    "# vectors[1] = torch.zeros(10)\n",
    "vectors = [[] for _ in range(3)]\n",
    "vectors[0] = [0.3, 0.7, 0.6, 0.9, 0.1]\n",
    "vectors[1] = [-0.3, 0.6, -0.8, 0.8, 0.8]\n",
    "vectors[2] = [0.1, -0.1, -0.6, -0.9, 0]\n",
    "vectors = [torch.tensor(vector) for vector in vectors]\n",
    "print(\"Original vectors:\")\n",
    "print(vectors)\n",
    "\n",
    "#test sort order\n",
    "#sort the vectors by average absolute value in descending order, dont use the function\n",
    "# avg_abs = [torch.mean(torch.abs(vectors[i])).item() for i in range(len(vectors))]\n",
    "# order = sorted(range(len(avg_abs)), key=lambda i: avg_abs[i], reverse=True)\n",
    "# vectors = [vectors[i] for i in order]\n",
    "# print(\"Sorted vectors:\")\n",
    "# print(vectors)\n",
    "\n",
    "\n",
    "\n",
    "#orthogonalize the vectors\n",
    "ortho_vectors = orthogonalize_vectors(vectors)\n",
    "print(\"Orthogonalized vectors:\")\n",
    "print(ortho_vectors)\n",
    "\n",
    "#use the vectorized version of the orthogonalization function\n",
    "ortho_vectors = orthogonalize_vectors_vectorized(vectors)\n",
    "print(\"Vectorized Orthogonalized vectors:\")\n",
    "print(ortho_vectors)\n",
    "\n",
    "#calculate the average change in the elements of the vectors for each vector\n",
    "change_vectors = [torch.mean(torch.abs(vectors[i] - ortho_vectors[i])).item() for i in range(len(vectors))]\n",
    "print(\"Average absolute Change vectors:\")\n",
    "print(change_vectors)\n",
    "\n",
    "#create a vector for each vector to record the change in the elements of the vectors after orthogonalization\n",
    "change_vectors = [-1*(vectors[i] - ortho_vectors[i]) for i in range(len(vectors))]\n",
    "print(\"Change vectors:\")\n",
    "print(change_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing of the orthogonalization vectorization algorithms and their effeciency\n",
    "Tests to be carried out:\n",
    "1. Ensure the results are the same\n",
    "2. Ensure the vectorized version is faster, with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
